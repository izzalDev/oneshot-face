{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw directory is set to: data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type              | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | embedding | Embedding         | 5.1 M  | train\n",
      "1 | distance  | EuclideanDistance | 0      | train\n",
      "2 | loss_fn   | ContrastiveLoss   | 0      | train\n",
      "--------------------------------------------------------\n",
      "5.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 M     Total params\n",
      "20.578    Total estimated model params size (MB)\n",
      "219       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/oneshot-face/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f00f55b3a274376ad20430fdbaccd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, Sampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models.mobilenetv2 import MobileNetV2\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set raw directory\n",
    "kaggle_path = 'kaggle/input/labeled-faces-in-the-wild-lfw-20180109/lfw'\n",
    "default_path = 'data/raw'\n",
    "raw_dir = kaggle_path if os.path.exists(kaggle_path) else default_path\n",
    "print(f'Raw directory is set to: {raw_dir}')\n",
    "\n",
    "# DATASET\n",
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_folder = datasets.ImageFolder(root=root_dir)\n",
    "        self.transform = transform\n",
    "        self.image_pairs = list(itertools.combinations_with_replacement(range(len(self.image_folder)), 2))\n",
    "        self.targets = [int(self.image_folder.targets[idx1] == self.image_folder.targets[idx2]) for idx1, idx2 in self.image_pairs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx1, idx2 = self.image_pairs[index]\n",
    "        img1, _ = self.image_folder[idx1]\n",
    "        img2, _ = self.image_folder[idx2]\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return img1, img2, self.targets[index]\n",
    "\n",
    "# SAMPLER & DATALOADER\n",
    "class RandomUnderSampler(Sampler):\n",
    "    def __init__(self, targets, seed=42, shuffle=False):\n",
    "        self.class_counts = Counter(targets)\n",
    "        self.indices = {cls: np.where(targets == cls)[0] for cls in self.class_counts.keys()}\n",
    "        self.seed = seed\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        sampled_indices = []\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        for _, indices in self.indices.items():\n",
    "            sampled_indices.extend(np.random.choice(indices, self.__min_count()))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(sampled_indices)\n",
    "        return iter(sampled_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__min_count() * len(self.class_counts.keys())\n",
    "\n",
    "    def __min_count(self):\n",
    "        return min(self.class_counts.values())\n",
    "\n",
    "# MODEL\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.backbone = MobileNetV2()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1280, 1280),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward_one_branch(self, x):\n",
    "        x = self.backbone.features(x)\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one_branch(input1)\n",
    "        output2 = self.forward_one_branch(input2)\n",
    "        return output1, output2\n",
    "\n",
    "class EuclideanDistance(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EuclideanDistance, self).__init__()\n",
    "\n",
    "    def forward(self, output1, output2):\n",
    "        return torch.sqrt(torch.sum((output1 - output2) ** 2))\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, distance, label):\n",
    "        loss_negative = (1 - label) * distance ** 2\n",
    "        loss_positive = label * torch.clamp(self.margin - distance, min=0) ** 2\n",
    "        loss = torch.mean(loss_negative + loss_positive)\n",
    "        return loss\n",
    "\n",
    "class sMobileNetV2(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(sMobileNetV2, self).__init__()\n",
    "        self.embedding = Embedding()\n",
    "        self.distance = EuclideanDistance()\n",
    "        self.loss_fn = ContrastiveLoss(margin=1.0)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return self.embedding(x1, x2)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img1, img2, label = batch\n",
    "        out1, out2 = self.forward(img1, img2)\n",
    "        dist = self.distance(out1, out2)\n",
    "        loss = self.loss_fn(dist, label)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "# Setup dataset and dataloader\n",
    "ds = SiameseDataset(raw_dir)\n",
    "ds.transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "sampler = RandomUnderSampler(np.array(ds.targets), seed=42)\n",
    "dl = torch.utils.data.DataLoader(ds, sampler=sampler, batch_size=8)\n",
    "\n",
    "# Setup and start training\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    max_steps=100\n",
    ")\n",
    "\n",
    "model = sMobileNetV2()\n",
    "trainer.fit(model, dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oneshot-face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
